{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyODxuq8hfcq1nhAShn6luz/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NitishGadde/Nitish-Homework-2/blob/main/README.md\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Udg3QjA8FvTn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Home Assignment 2 - Neural Networks and Deep Learning\n",
        "**Student:** Sai Nitish Gadde (700758589)\n",
        "**Spring 2025**\n",
        "\n",
        "\n",
        "## Overview  \n",
        "This repository contains the implementation and demonstration of **Home Assignment 2**, covering the following topics:  \n",
        "- **Cloud Computing for Deep Learning** (Elasticity & Scalability, AWS SageMaker vs. Google Vertex AI vs. Azure ML)  \n",
        "- **Convolution Operations with Different Parameters**  \n",
        "- **CNN Feature Extraction (Sobel Filters & Pooling)**  \n",
        "- **CNN Architectures (AlexNet & ResNet)**  \n",
        "\n",
        "Each section includes Python scripts demonstrating the concepts using **TensorFlow, OpenCV, and NumPy**.\n",
        "\n",
        "\n",
        "## **1Ô∏è Cloud Computing for Deep Learning**\n",
        "###  **Elasticity vs. Scalability**\n",
        "- **Elasticity**: The ability of a cloud system to dynamically allocate resources based on demand. In deep learning, this helps in scaling up GPUs/TPUs when needed and reducing resources when idle.  \n",
        "- **Scalability**: The system's ability to handle an increasing workload by adding more resources. This ensures efficient training of deep learning models on large datasets.\n",
        "\n",
        "###  **Comparison of Cloud Platforms for Deep Learning**\n",
        "| Feature | AWS SageMaker | Google Vertex AI | Azure ML Studio |\n",
        "|---------|-------------|----------------|-----------------|\n",
        "| **Ease of Use** | Jupyter notebooks & automated ML | AutoML & pipelines | No-code UI & ML pipelines |\n",
        "| **Compute Support** | GPUs, AWS Inferentia | GPUs, TPUs | NVIDIA GPUs, FPGAs |\n",
        "| **AutoML** | Built-in AutoML | Strong AutoML support | Drag-and-drop AutoML |\n",
        "| **Model Deployment** | One-click inference endpoints | AI pipelines | MLOps & batch inference |\n",
        "| **Best For** | AWS users | Large-scale AI with TPUs | Microsoft enterprise users |\n",
        "\n",
        " **Conclusion**: AWS is best for AWS users, Vertex AI for large-scale AI workloads, and Azure ML for enterprises using Microsoft services.\n",
        "\n",
        "---\n",
        "\n",
        "## **2Ô∏è Convolution Operations with Different Parameters**\n",
        "### ** Code Overview**\n",
        "This section demonstrates convolution operations on a **5√ó5 matrix** using a **3√ó3 kernel**, varying stride and padding.\n",
        "\n",
        "#### **Python Implementation**\n",
        "```python\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D\n",
        "\n",
        "# Define input matrix\n",
        "input_matrix = np.array([[1, 2, 3, 4, 5],\n",
        "                         [6, 7, 8, 9, 10],\n",
        "                         [11, 12, 13, 14, 15],\n",
        "                         [16, 17, 18, 19, 20],\n",
        "                         [21, 22, 23, 24, 25]], dtype=np.float32).reshape(1, 5, 5, 1)\n",
        "\n",
        "# Define convolution kernel\n",
        "kernel = np.array([[1, 0, -1],\n",
        "                   [1, 0, -1],\n",
        "                   [1, 0, -1]], dtype=np.float32).reshape(3, 3, 1, 1)\n",
        "\n",
        "# Apply convolution function\n",
        "def apply_convolution(stride, padding):\n",
        "    input_layer = Input(shape=(5, 5, 1))\n",
        "    conv_layer = Conv2D(filters=1, kernel_size=(3, 3), strides=stride, padding=padding,\n",
        "                         kernel_initializer=tf.keras.initializers.Constant(kernel), use_bias=False)(input_layer)\n",
        "    model = Model(inputs=input_layer, outputs=conv_layer)\n",
        "    output = model.predict(input_matrix)\n",
        "    return output.squeeze()\n",
        "\n",
        "# Run different convolutions\n",
        "output_valid = apply_convolution(1, 'valid')\n",
        "output_same = apply_convolution(1, 'same')\n",
        "\n",
        "print(\"Output (Stride=1, Padding='VALID'):\\n\", output_valid)\n",
        "print(\"\\nOutput (Stride=1, Padding='SAME'):\\n\", output_same)\n",
        "```\n",
        "####  **Results & Observations**\n",
        "- **Padding = 'VALID'** removes the border, producing a smaller output.  \n",
        "- **Padding = 'SAME'** maintains the input size by adding zero-padding.  \n",
        "- Increasing **stride** reduces the output size.\n",
        "\n",
        "---\n",
        "\n",
        "## **3Ô∏è CNN Feature Extraction (Sobel Filters & Pooling)**\n",
        "###  **Edge Detection Using Sobel Filter**\n",
        "- The **Sobel filter** detects edges by calculating gradients in the **X** and **Y** directions.\n",
        "- Implemented using OpenCV and Matplotlib.\n",
        "\n",
        "####  **Python Code**\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def apply_sobel_filter(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
        "    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    plt.subplot(1, 3, 1); plt.imshow(image, cmap=\"gray\"); plt.title(\"Original\")\n",
        "    plt.subplot(1, 3, 2); plt.imshow(sobel_x, cmap=\"gray\"); plt.title(\"Sobel-X\")\n",
        "    plt.subplot(1, 3, 3); plt.imshow(sobel_y, cmap=\"gray\"); plt.title(\"Sobel-Y\")\n",
        "    plt.show()\n",
        "\n",
        "# Usage: apply_sobel_filter('image.jpg')\n",
        "\n",
        "üìå **Conclusion**: Sobel-X detects **vertical edges**, while Sobel-Y detects **horizontal edges**.\n",
        "\n",
        "### üîπ **Max Pooling vs. Average Pooling**\n",
        "- **Max Pooling** retains the highest pixel value.\n",
        "- **Average Pooling** computes the mean pixel value.\n",
        "from tensorflow.keras.layers import MaxPooling2D, AveragePooling2D\n",
        "\n",
        "input_matrix = np.random.randint(0, 256, (1, 4, 4, 1), dtype=np.int32).astype(np.float32)\n",
        "max_pool = MaxPooling2D(pool_size=(2, 2), strides=2)(tf.convert_to_tensor(input_matrix))\n",
        "avg_pool = AveragePooling2D(pool_size=(2, 2), strides=2)(tf.convert_to_tensor(input_matrix))\n",
        "\n",
        "print(\"\\nMax Pooled Matrix:\\n\", max_pool.numpy().squeeze())\n",
        "print(\"\\nAverage Pooled Matrix:\\n\", avg_pool.numpy().squeeze())\n",
        "```\n",
        "üìå **Conclusion**: Max pooling is better for detecting edges, while average pooling smooths images.\n",
        "\n",
        "\n",
        "\n",
        "## **4Ô∏è CNN Architectures (AlexNet & ResNet)**\n",
        "### **AlexNet**\n",
        "- Introduced deep CNNs with **ReLU activations**, **dropout**, and **overlapping pooling**.\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "def alexnet():\n",
        "    model = Sequential([\n",
        "        Conv2D(96, (11, 11), strides=4, activation='relu', input_shape=(227, 227, 3)),\n",
        "        MaxPooling2D((3, 3), strides=2),\n",
        "        Conv2D(256, (5, 5), activation='relu', padding='same'),\n",
        "        MaxPooling2D((3, 3), strides=2),\n",
        "        Flatten(),\n",
        "        Dense(4096, activation='relu'),\n",
        "        Dropout(0.5),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.summary()\n",
        "\n",
        "alexnet()\n",
        "```\n",
        "üìå **Conclusion**: AlexNet improved accuracy in ImageNet classification.\n",
        "\n",
        "### üîπ **ResNet (Residual Networks)**\n",
        "- Introduced **skip connections** to prevent the vanishing gradient problem.\n",
        "\n",
        "from tensorflow.keras.layers import Input, Add\n",
        "\n",
        "def resnet():\n",
        "    input_layer = Input(shape=(224, 224, 3))\n",
        "    x = Conv2D(64, (7, 7), strides=2, padding='same', activation='relu')(input_layer)\n",
        "    x = Add()([x, input_layer])  # Skip Connection\n",
        "    model = Model(inputs=input_layer, outputs=x)\n",
        "    model.summary()\n",
        "\n",
        "resnet()\n",
        "\n",
        "üìå **Conclusion**: ResNet allows deeper networks by avoiding gradient vanishing.\n",
        "\n",
        "\n",
        "\n",
        "üìå **How to Run the Code**\n",
        "1. Install dependencies: `pip install tensorflow numpy opencv-python matplotlib`\n",
        "2. Run scripts in **Google Colab or Jupyter Notebook**.\n",
        "\n",
        "**Thank you for checking out my assignment!**\n",
        "\n",
        "\n",
        "Let me know if you need any modifications! üöÄ"
      ],
      "metadata": {
        "id": "XyT9IJlBFv_D"
      }
    }
  ]
}